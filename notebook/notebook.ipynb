{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "title",
   "metadata": {
    "id": "title"
   },
   "source": [
    "# Variational Autoencoders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "js_build",
   "metadata": {
    "id": "js_build"
   },
   "outputs": [],
   "source": [
    "import subprocess\n",
    "\n",
    "subprocess.run([\"npm\", \"i\", \"--no-progress\"], cwd=\"../widgets\", check=True)\n",
    "subprocess.run([\"npm\", \"i\", \"--no-progress\"], cwd=\"widget-wrappers\", check=True)\n",
    "subprocess.run([\"bash\", \"build_wrapped_widgets.sh\"], cwd=\"widget-wrappers\", check=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "imports",
   "metadata": {
    "id": "imports"
   },
   "outputs": [],
   "source": [
    "import math\n",
    "\n",
    "import torch\n",
    "import numpy as np\n",
    "import torch.nn as nn\n",
    "from tqdm.notebook import trange\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from vaewidgets import *\n",
    "from dataset import generate_dataset\n",
    "from util import map_tuple, BatchIterator, plot_losses, onnx_export\n",
    "from constants import size_range, hue_range, sidelength, latent_dim"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c691c637",
   "metadata": {},
   "source": [
    "## Loss function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9cfc3a80",
   "metadata": {},
   "outputs": [],
   "source": [
    "def kl_divergence(mu, logvar):\n",
    "    \"\"\"\n",
    "    KL divergence between N(mu, sigma^2) and N(0, 1), per sample.\n",
    "    mu, logvar: tensors of shape [batch_size, latent_dim]\n",
    "    Returns: tensor of shape [batch_size]\n",
    "    \"\"\"\n",
    "    return 0.5 * torch.sum(torch.exp(logvar) + mu**2 - 1 - logvar, dim=1)\n",
    "\n",
    "\n",
    "def log_normal_diag_spherical(x, mu, sigma2):\n",
    "    \"\"\"\n",
    "    Computes log N(x; mu, sigma^2 I) for image tensors.\n",
    "\n",
    "    Args:\n",
    "        x: [B, C, H, W]\n",
    "        mu: [B, C, H, W]\n",
    "        sigma2: scalar (fixed variance)\n",
    "\n",
    "    Returns:\n",
    "        log_probs: [B] — per-sample log likelihoods\n",
    "    \"\"\"\n",
    "    B = x.size(0)\n",
    "    d = x[0].numel()  # total dims per sample\n",
    "    squared_error = (x - mu).pow(2).view(B, -1).sum(dim=1)\n",
    "\n",
    "    const_term = -0.5 * d * math.log(2 * math.pi)\n",
    "    log_sigma_term = -0.5 * d * math.log(sigma2)\n",
    "    quad_term = -0.5 / sigma2 * squared_error\n",
    "    return const_term + log_sigma_term + quad_term\n",
    "\n",
    "\n",
    "def approximate_elbo(xi, mu_z, mu_xi, logvar_xi, sigma2):\n",
    "    \"\"\"\n",
    "    Approximates ELBO for each data point xi.\n",
    "\n",
    "    Args:\n",
    "        xi: [batch_size, input_dim] — true input data\n",
    "        mu_z: [batch_size, input_dim] — decoder output (mean of p(x|z))\n",
    "        mu_xi, logvar_xi: [batch_size, latent_dim] — encoder outputs\n",
    "        sigma2: scalar — reconstruction variance\n",
    "\n",
    "    Returns:\n",
    "        elbo: [batch_size] — per-sample ELBO\n",
    "    \"\"\"\n",
    "    assert len(xi.shape) == 2, \"xi must be a 2D tensor\"\n",
    "    assert len(mu_z.shape) == 2, \"mu_z must be a 2D tensor\"\n",
    "    assert len(mu_xi.shape) == 2, \"mu_xi must be a 2D tensor\"\n",
    "    assert len(logvar_xi.shape) == 2, \"logvar_xi must be a 2D tensor\"\n",
    "\n",
    "    assert xi.shape == mu_z.shape, \"xi and mu_z must have the same shape\"\n",
    "    assert mu_xi.shape == logvar_xi.shape, \"mu_xi and logvar_xi must have the same shape\"\n",
    "    assert sigma2 > 0, \"sigma2 must be positive\"\n",
    "\n",
    "    recon_term = log_normal_diag_spherical(xi, mu_z, sigma2)\n",
    "    kl_term = kl_divergence(mu_xi, logvar_xi)\n",
    "    beta = 1.0  # default beta value, can be adjusted\n",
    "    # return recon_term - kl_term\n",
    "    return recon_term - beta * kl_term  # ELBO = log p(x|z) - KL(q(z|x) || p(z))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dataset_explanation",
   "metadata": {
    "id": "dataset_explanation"
   },
   "source": [
    "## Dataset explanation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dataset_explanation_code",
   "metadata": {
    "id": "dataset_explanation_code"
   },
   "outputs": [],
   "source": [
    "dataset_explanation()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "train_validatation_set_split",
   "metadata": {
    "id": "train_validatation_set_split"
   },
   "source": [
    "## Train/validation set split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "valset_selection",
   "metadata": {
    "id": "valset_selection"
   },
   "outputs": [],
   "source": [
    "valset_selection = AreaSelectionWidget(size_range, hue_range, \"Size\", \"Hue\", 0.6, 0.4, 0.3, 0.3)\n",
    "valset_selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dataset_generation",
   "metadata": {
    "id": "dataset_generation"
   },
   "outputs": [],
   "source": [
    "trainset_coords, valset_coords, trainset, valset = generate_dataset(\n",
    "    size_range=size_range,\n",
    "    hue_range=hue_range,\n",
    "    valset_size_range=(valset_selection.x, valset_selection.x + valset_selection.width),\n",
    "    valset_hue_range=(valset_selection.y, valset_selection.y + valset_selection.height),\n",
    "    num_samples=2000,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cc2c8d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_visualization(trainset_coords, valset_coords, trainset, valset)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c15ff050",
   "metadata": {},
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c44edfec",
   "metadata": {},
   "outputs": [],
   "source": [
    "def reparameterize(mu, logvar):\n",
    "    std = torch.exp(0.5 * logvar)\n",
    "    eps = torch.randn_like(std)\n",
    "    return mu + eps * std\n",
    "\n",
    "\n",
    "class Encoder(nn.Module):\n",
    "    def __init__(self, latent_dim=2):\n",
    "        super().__init__()\n",
    "        self.conv = nn.Sequential(\n",
    "            nn.Conv2d(3, 32, 3, stride=2, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(32, 64, 3, stride=2, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(64, 128, 3, stride=2, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.Flatten(),\n",
    "        )\n",
    "        self.fc_mu = nn.Linear(128 * 4 * 4, latent_dim)\n",
    "        self.fc_logvar = nn.Linear(128 * 4 * 4, latent_dim)\n",
    "\n",
    "    def forward(self, x):\n",
    "        h = self.conv(x)\n",
    "        return self.fc_mu(h), self.fc_logvar(h)\n",
    "\n",
    "\n",
    "class Decoder(nn.Module):\n",
    "    def __init__(self, latent_dim=2):\n",
    "        super().__init__()\n",
    "        self.fc = nn.Linear(latent_dim, 128 * 4 * 4)\n",
    "        self.deconv = nn.Sequential(\n",
    "            nn.ReLU(),\n",
    "            nn.ConvTranspose2d(128, 64, 4, stride=2, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.ConvTranspose2d(64, 32, 4, stride=2, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.ConvTranspose2d(32, 3, 4, stride=2, padding=1),\n",
    "            nn.Sigmoid(),\n",
    "        )\n",
    "\n",
    "    def forward(self, z):\n",
    "        h = self.fc(z).view(-1, 128, 4, 4)\n",
    "        return self.deconv(h)\n",
    "\n",
    "\n",
    "class VAE(nn.Module):\n",
    "    def __init__(self, latent_dim):\n",
    "        super().__init__()\n",
    "        self.encoder = Encoder(latent_dim)\n",
    "        self.decoder = Decoder(latent_dim)\n",
    "\n",
    "    def forward(self, x):\n",
    "        mu_x, logvar_x = self.encoder(x)\n",
    "        z = reparameterize(mu_x, logvar_x)\n",
    "        mu_z = self.decoder(z)\n",
    "        return mu_x, logvar_x, z, mu_z"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "412c3244",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba0bba61",
   "metadata": {},
   "outputs": [],
   "source": [
    "if torch.cuda.is_available():\n",
    "    device = torch.device(\"cuda\")\n",
    "elif torch.backends.mps.is_available():\n",
    "    device = torch.device(\"mps\")\n",
    "else:\n",
    "    device = torch.device(\"cpu\")\n",
    "\n",
    "vae = VAE(latent_dim=2).to(device)\n",
    "optimizer = torch.optim.Adam(vae.parameters(), lr=1e-3)\n",
    "\n",
    "train_losses = []\n",
    "val_losses = []\n",
    "val_mses = []\n",
    "best_val_loss = float(\"inf\")\n",
    "\n",
    "batch_size = 256\n",
    "num_epochs = 100\n",
    "pbar = trange(num_epochs)\n",
    "for epoch in pbar:\n",
    "    vae.train()\n",
    "    per_batch_train_losses = []\n",
    "    batch_iterator = BatchIterator(trainset, batch_size)\n",
    "    for batch in batch_iterator:\n",
    "        x = (batch / 255.0).to(device)\n",
    "        mu_x, logvar_x, _, mu_z = vae(x)\n",
    "        loss = -approximate_elbo(\n",
    "            x.view(x.shape[0], sidelength * sidelength * 3),\n",
    "            mu_z.view(mu_z.shape[0], sidelength * sidelength * 3),\n",
    "            mu_x,\n",
    "            logvar_x,\n",
    "            sigma2=1.0,\n",
    "        ).mean()\n",
    "        per_batch_train_losses.append(loss.item())\n",
    "        optimizer.zero_grad()\n",
    "        loss.mean().backward()\n",
    "        optimizer.step()\n",
    "    train_losses.append(np.mean(per_batch_train_losses))\n",
    "\n",
    "    per_batch_val_losses = []\n",
    "    vae.eval()\n",
    "    with torch.no_grad():\n",
    "        batch_iterator = BatchIterator(valset, batch_size)\n",
    "        for batch in batch_iterator:\n",
    "            x = (batch / 255.0).to(device)\n",
    "            mu_x, logvar_x, _, mu_z = vae(x)\n",
    "            loss = -approximate_elbo(\n",
    "                x.view(x.shape[0], sidelength * sidelength * 3),\n",
    "                mu_z.view(mu_z.shape[0], sidelength * sidelength * 3),\n",
    "                mu_x,\n",
    "                logvar_x,\n",
    "                sigma2=1.0,\n",
    "            ).mean()\n",
    "            per_batch_val_losses.append(loss.item())\n",
    "    pbar.set_description(\n",
    "        f\"Train Loss: {train_losses[-1]:.4f}, Val Loss: {np.mean(per_batch_val_losses):.4f}\"\n",
    "    )\n",
    "    epoch_val_loss = np.mean(per_batch_val_losses)\n",
    "    val_losses.append(epoch_val_loss)\n",
    "\n",
    "    if epoch > float(num_epochs) * 0.75 and epoch_val_loss < best_val_loss:\n",
    "        best_val_loss = epoch_val_loss\n",
    "        torch.save(vae.state_dict(), \"vae.pth\")\n",
    "\n",
    "plot_losses(train_losses, val_losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b7d33d2-5e7d-466d-a4f8-37d8bba79e57",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the best model again and export to ONNX so we can use it in the browser\n",
    "vae = VAE(latent_dim=latent_dim)\n",
    "vae.load_state_dict(torch.load(\"vae.pth\"))\n",
    "vae.eval()\n",
    "encoder, decoder = onnx_export(vae)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94bdaa6d-5b70-4784-aa1e-209b7e8659a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "mapping(\n",
    "    encoder,\n",
    "    decoder,\n",
    "    [\n",
    "        [valset_selection.x, valset_selection.x + valset_selection.width],\n",
    "        [valset_selection.y, valset_selection.y + valset_selection.height],\n",
    "    ],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90b5dc5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "decoding(encoder, decoder)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
